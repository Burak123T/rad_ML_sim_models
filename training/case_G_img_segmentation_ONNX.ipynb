{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1745396711457,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "uOuf8y8YSe0l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18154,
     "status": "ok",
     "timestamp": 1745396731652,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "4jbf9XnWdC6N",
    "outputId": "654871af-a0d0-4802-937c-48026de8c1b8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1745396734728,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "QzCd9cECdQTq",
    "outputId": "c5ccc8e5-a148-4182-aa4c-b0be8ca7e99d"
   },
   "outputs": [],
   "source": [
    "model_save_dir = \"/content/drive/My Drive/my_keras_models/sar_ship_detect_models/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "# exist_ok=True prevents error if directory already exists\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "model_filepath = os.path.join(model_save_dir, \"models\")\n",
    "\n",
    "print(f\"Model filepath for saving new models: {model_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2425,
     "status": "ok",
     "timestamp": 1745240484882,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "VE_aBbTYeXX9",
    "outputId": "b40562b2-a12b-47cb-cdba-947cfb951f82"
   },
   "outputs": [],
   "source": [
    "!apt-get install unrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 66149,
     "status": "ok",
     "timestamp": 1745240557979,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "FA5jaTN_eatz",
    "outputId": "d34aba1f-c64e-42a6-932e-76597da256ec"
   },
   "outputs": [],
   "source": [
    "!unrar x \"/content/drive/My Drive/Colab Notebooks/Datasets/SSDD_coco.rar\" \"/content/drive/My Drive/ColabNotebooks/Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6738,
     "status": "ok",
     "timestamp": 1745396749167,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "fZZzwphxfqRu",
    "outputId": "7c682d35-90bf-4171-abc8-7779776dfd0c"
   },
   "outputs": [],
   "source": [
    "data_folder = \"/content/drive/My Drive/ColabNotebooks/Datasets/SSDD_coco/\"\n",
    "\n",
    "img_num = 0\n",
    "json_num = 0\n",
    "\n",
    "CATEGORIES = os.listdir(data_folder)\n",
    "for cat in CATEGORIES:\n",
    "  if cat.endswith('.json'):\n",
    "    json_num += 1\n",
    "  else:\n",
    "    img_num += 1\n",
    "\n",
    "print(f\"number of images: {img_num}\")\n",
    "print(f\"number of corresponding JSON data: {json_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6470,
     "status": "ok",
     "timestamp": 1745396762607,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "y8Z_pqsig5h6",
    "outputId": "30813735-9653-46c1-ded7-377a1d2840b4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # --- Encoder (Contracting Path) ---\n",
    "    # Block 1: 32 filters\n",
    "    c1 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = layers.Dropout(0.1)(c1)\n",
    "    c1 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Block 2: 64 filters\n",
    "    c2 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = layers.Dropout(0.1)(c2)\n",
    "    c2 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Block 3: 128 filters\n",
    "    c3 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = layers.Dropout(0.2)(c3)\n",
    "    c3 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Block 4: 256 filters\n",
    "    c4 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = layers.Dropout(0.2)(c4)\n",
    "    c4 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    # --- Bottleneck: 512 filters ---\n",
    "    c5 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = layers.Dropout(0.3)(c5)\n",
    "    c5 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    # --- Decoder (Expansive Path) ---\n",
    "    # Block 6: 256 filters\n",
    "    u6 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5) # Upsample to match c4 spatial dims\n",
    "    u6 = layers.concatenate([u6, c4], axis=-1) # Skip Connection from c4 (256 filters)\n",
    "    c6 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = layers.Dropout(0.2)(c6)\n",
    "    c6 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    # Block 7: 128 filters\n",
    "    u7 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6) # Upsample to match c3 spatial dims\n",
    "    u7 = layers.concatenate([u7, c3], axis=-1) # Skip Connection from c3 (128 filters)\n",
    "    c7 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = layers.Dropout(0.2)(c7)\n",
    "    c7 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    # Block 8: 64 filters\n",
    "    u8 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7) # Upsample to match c2 spatial dims\n",
    "    u8 = layers.concatenate([u8, c2], axis=-1) # Skip Connection from c2 (64 filters)\n",
    "    c8 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = layers.Dropout(0.1)(c8)\n",
    "    c8 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    # Block 9: 32 filters\n",
    "    u9 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8) # Upsample to match c1 spatial dims\n",
    "    u9 = layers.concatenate([u9, c1], axis=-1) # Skip Connection from c1 (32 filters)\n",
    "    c9 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = layers.Dropout(0.1)(c9)\n",
    "    c9 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    # --- Output Layer ---\n",
    "    # 1x1 Convolution to map features to the single output channel (ship probability)\n",
    "    # Use 'sigmoid' activation for binary (0 or 1) segmentation\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    # --- Create Model ---\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model\n",
    "\n",
    "# --- Instantiate and Compile the Model ---\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "# Build the U-Net model\n",
    "unet_model = build_unet(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "# Use 'binary_crossentropy' for sigmoid output and masks with 0s and 1s.\n",
    "unet_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy']) # 'accuracy' here is pixel-wise accuracy\n",
    "\n",
    "# Print the model summary\n",
    "print(\"Defined U-Net model architecture:\")\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1745396772556,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "rCJTn509wYYY",
    "outputId": "e4e8634d-4157-4c6a-c9c6-5a191a382f1b"
   },
   "outputs": [],
   "source": [
    "print(\"Loading in data...\")\n",
    "\n",
    "data_files = []\n",
    "\n",
    "image_files = sorted(tf.io.gfile.glob(os.path.join(data_folder, '*.jpg')))\n",
    "json_files = sorted(tf.io.gfile.glob(os.path.join(data_folder, '*.json')))\n",
    "\n",
    "print(f\"Found {len(image_files)} JPEG image files.\")\n",
    "print(f\"Found {len(json_files)} JSON files.\")\n",
    "\n",
    "json_dict = {os.path.splitext(os.path.basename(_file))[0]: _file for _file in json_files}\n",
    "\n",
    "for img_path in image_files:\n",
    "    path_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    json_path = json_dict[path_name]\n",
    "    data_files.append({'image': img_path, 'json': json_path})\n",
    "    print(f\"Appended {os.path.basename(img_path)} with {os.path.basename(json_path)}\")\n",
    "\n",
    "print(f\"\\nSuccessfully added {len(data_files)} image/json files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1745396780312,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "LoZgVEiDbcop",
    "outputId": "653dc868-6c30-41a8-b14e-6f74ff1fa898"
   },
   "outputs": [],
   "source": [
    "_image_paths = [data['image'] for data in data_files]\n",
    "_json_paths = [data['json'] for data in data_files]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_train, img_test, json_train, json_test = train_test_split(_image_paths, _json_paths, test_size=0.2, random_state=42)\n",
    "print(\"Splitting data success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1745396788808,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "qty-Lm5eXnQT"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2  # Make sure OpenCV is installed: !pip install opencv-python\n",
    "import os\n",
    "\n",
    "# Define the target image dimensions (should match your model's expected input/output spatial size)\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "\n",
    "def create_mask_from_json(json_path, target_dims=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    # 1. Initialize an empty mask (background class = 0)\n",
    "    #    Using uint8 is compatible with cv2.fillPoly and common for masks.\n",
    "    mask = np.zeros(target_dims, dtype=np.uint8)\n",
    "\n",
    "    try:\n",
    "        # 2. Check if JSON file exists\n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"Warning: JSON file not found at {json_path}\")\n",
    "            return mask # Return empty mask if JSON doesn't exist\n",
    "\n",
    "        # 3. Load JSON data\n",
    "        with open(json_path, 'r') as f:\n",
    "            annotation_data = json.load(f)\n",
    "\n",
    "        # 4. Get original image dimensions (needed for scaling coordinates)\n",
    "        #    These keys might vary ('imageHeight', 'image_height', etc.) - check your JSON!\n",
    "        original_height = annotation_data.get('imageHeight')\n",
    "        original_width = annotation_data.get('imageWidth')\n",
    "\n",
    "        # Basic validation of dimensions\n",
    "        if original_height is None or original_width is None or original_height <= 0 or original_width <= 0:\n",
    "             # If original dims aren't available or invalid, we can't scale accurately.\n",
    "             # We could either raise an error, return empty mask, or try proceeding without scaling\n",
    "             # (assuming coordinates might already be relative to target_dims, which is risky).\n",
    "             print(f\"Warning: Valid original image dimensions not found or invalid in {json_path}. Cannot create accurate mask.\")\n",
    "             return mask # Return empty mask\n",
    "\n",
    "        # 5. Calculate scaling factors if target dims differ from original\n",
    "        scale_y = target_dims[0] / original_height\n",
    "        scale_x = target_dims[1] / original_width\n",
    "\n",
    "        # 6. Find the list of annotated shapes (common key is 'shapes')\n",
    "        #    This key might also vary ('objects', 'annotations', etc.) - check your JSON!\n",
    "        shapes = annotation_data.get('shapes', [])\n",
    "        if not shapes:\n",
    "            # If no shapes are found, the mask remains empty (all background)\n",
    "            # print(f\"Debug: No 'shapes' array found or empty in {json_path}.\") # Optional debug print\n",
    "            pass # Continue, will return the empty mask\n",
    "\n",
    "        # 7. Iterate through shapes found in the JSON\n",
    "        for shape in shapes:\n",
    "            # Check if the label indicates a ship (case-insensitive check)\n",
    "            label = shape.get('label', '').lower()\n",
    "            shape_type = shape.get('shape_type', '').lower()\n",
    "\n",
    "            # Process only if it's a 'ship' and a 'polygon'\n",
    "            if label.startswith('ship') and shape_type == 'polygon':\n",
    "                points = shape.get('points', [])\n",
    "                # Need at least 3 points to form a valid polygon for filling\n",
    "                if len(points) >= 3:\n",
    "                    # Scale the polygon points from original dimensions to target dimensions\n",
    "                    scaled_points = np.array([(p[0] * scale_x, p[1] * scale_y) for p in points], dtype=np.int32)\n",
    "\n",
    "                    # Draw the filled polygon onto the mask\n",
    "                    # cv2.fillPoly expects a list of polygons, hence [scaled_points]\n",
    "                    # It fills the polygon area with the specified color (1 for ship)\n",
    "                    cv2.fillPoly(mask, [scaled_points], color=(1))\n",
    "                else:\n",
    "                     print(f\"Warning: Ship polygon with < 3 points found in {json_path}. Skipping this shape.\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON file: {json_path}\")\n",
    "        return np.zeros(target_dims, dtype=np.uint8) # Return empty mask on parsing error\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors during processing\n",
    "        print(f\"An unexpected error occurred processing {json_path}: {e}\")\n",
    "        return np.zeros(target_dims, dtype=np.uint8) # Return empty mask on other errors\n",
    "\n",
    "    # 8. Return the final mask\n",
    "    print(\"Created mask\")\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295615,
     "status": "ok",
     "timestamp": 1745397089361,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "TpKdCzyxaLk8",
    "outputId": "711c48a4-ecfe-4488-d5b3-9b0db2507625"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "# --- Define Constants ---\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 3  # Assuming RGB based on cv2.imread and cvtColor\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 5\n",
    "\n",
    "# --- tf.data Loading and Preprocessing Function ---\n",
    "# This function will be mapped over the dataset of file paths.\n",
    "def load_and_preprocess(image_path_tensor, json_path_tensor):\n",
    "    # 1. Define Python wrapper for mask creation (needed for tf.py_function)\n",
    "    # This function takes the byte tensor from tf.py_function, decodes it,\n",
    "    # and calls your existing Python mask creation function.\n",
    "    def _create_mask_py(json_path_bytes):\n",
    "        json_path = json_path_bytes.numpy().decode('utf-8')\n",
    "        # Call your existing function to create the mask\n",
    "        mask_np = create_mask_from_json(json_path, target_dims=(IMG_HEIGHT, IMG_WIDTH))\n",
    "        # Ensure dtype is float32 for binary_crossentropy loss\n",
    "        return mask_np.astype(np.float32)\n",
    "\n",
    "    # 2. Load and preprocess image using TensorFlow ops (more efficient within tf.data)\n",
    "    img_bytes = tf.io.read_file(image_path_tensor)\n",
    "    # Use decode_jpeg since original files are .jpg\n",
    "    img = tf.io.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
    "    # Resize using tf.image (ensure size matches mask target_dims and model input)\n",
    "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    # Normalize\n",
    "    img = img / 255.0\n",
    "    # Ensure correct dtype\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    # Explicitly setting shape can sometimes help TF optimize\n",
    "    img.set_shape([IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "\n",
    "    # 3. Create mask using tf.py_function\n",
    "    # tf.py_function wraps your Python code so TF can call it during mapping.\n",
    "    mask = tf.py_function(\n",
    "        func=_create_mask_py,        # The Python function wrapper to call\n",
    "        inp=[json_path_tensor],      # Input tensor (the json path)\n",
    "        Tout=tf.float32              # Expected output data type from the Python function\n",
    "    )\n",
    "    # Set shape for the mask tensor (H, W). Crucial for model compatibility!\n",
    "    mask.set_shape([IMG_HEIGHT, IMG_WIDTH])\n",
    "    # Add channel dimension -> (H, W, 1), as expected by the U-Net output/loss\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # Return the processed image and mask as a tuple\n",
    "    return img, mask\n",
    "\n",
    "# --- Create tf.data Datasets ---\n",
    "print(\"Creating tf.data datasets...\")\n",
    "\n",
    "# Create datasets from the lists of file paths\n",
    "# Slices the lists, so each element of the dataset is (image_path_string, json_path_string)\n",
    "train_ds_raw = tf.data.Dataset.from_tensor_slices((img_train, json_train))\n",
    "val_ds_raw = tf.data.Dataset.from_tensor_slices((img_test, json_test)) # Use test split for validation\n",
    "\n",
    "# Use AUTOTUNE for optimal parallel processing and prefetching\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# --- Build the Training Dataset Pipeline ---\n",
    "print(\"Building training pipeline...\")\n",
    "train_dataset = train_ds_raw \\\n",
    "    .map(load_and_preprocess, num_parallel_calls=AUTOTUNE) \\\n",
    "    .shuffle(buffer_size=len(img_train)) \\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .prefetch(buffer_size=AUTOTUNE) # Prepares next batches while GPU is busy\n",
    "\n",
    "# --- Build the Validation Dataset Pipeline ---\n",
    "print(\"Building validation pipeline...\")\n",
    "val_dataset = val_ds_raw \\\n",
    "    .map(load_and_preprocess, num_parallel_calls=AUTOTUNE) \\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"Datasets created successfully.\")\n",
    "# Verify the output structure, shape, and types of the datasets\n",
    "print(\"Training Dataset Element Spec:\", train_dataset.element_spec)\n",
    "print(\"Validation Dataset Element Spec:\", val_dataset.element_spec)\n",
    "\n",
    "\n",
    "# --- Train the Model using the tf.data Datasets ---\n",
    "print(\"\\nStarting model training...\")\n",
    "\n",
    "NUM_TRAIN_SAMPLES = len(img_train)\n",
    "NUM_VAL_SAMPLES = len(img_test) # Using test set as validation set here\n",
    "\n",
    "# Calculate steps per epoch - important if dataset could repeat indefinitely\n",
    "# Using math.ceil ensures all samples are seen even if not perfectly divisible\n",
    "steps_per_epoch = math.ceil(NUM_TRAIN_SAMPLES / BATCH_SIZE)\n",
    "validation_steps = math.ceil(NUM_VAL_SAMPLES / BATCH_SIZE)\n",
    "\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Training Steps per Epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation Steps per Epoch: {validation_steps}\")\n",
    "\n",
    "# Now call model.fit with the tf.data.Dataset objects\n",
    "history = unet_model.fit(\n",
    "    train_dataset,               # Pass the training dataset object\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset, # Pass the validation dataset object\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")\n",
    "\n",
    "print(\"\\nModel training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1745397097599,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "N2qwSshSHcCI",
    "outputId": "9ee41950-dbb9-4526-acd9-17e42a9497ad"
   },
   "outputs": [],
   "source": [
    "unet_model.export(model_filepath)\n",
    "print(f\"Model saved to: {model_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1745397106365,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "pzQiAL8oEF6B",
    "outputId": "b9510c34-b990-4d0a-d6a9-42eef0fbff7c"
   },
   "outputs": [],
   "source": [
    "# Optional: Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()), 1]) # Adjust ylim if needed\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 7697,
     "status": "ok",
     "timestamp": 1745397121606,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "ErwRiD7fHcww",
    "outputId": "efd72347-5257-4c08-afc7-6b1f636363a6"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11986,
     "status": "ok",
     "timestamp": 1745397144635,
     "user": {
      "displayName": "Burak Özdemir",
      "userId": "17976192270088828496"
     },
     "user_tz": -120
    },
    "id": "D5hkW-glHguL",
    "outputId": "c7693ee2-67e0-4a33-bde5-caf87b30525e"
   },
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Get the tf2onnx installation directory\n",
    "tf2onnx_dir = os.path.dirname(tf2onnx.__file__)\n",
    "tfonnx_path = os.path.join(tf2onnx_dir, \"tfonnx.py\")\n",
    "\n",
    "print(f\"Attempting to patch tf2onnx file at: {tfonnx_path}\")\n",
    "\n",
    "try:\n",
    "    with open(tfonnx_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Replace np.cast with np.asarray in the specific function\n",
    "    updated_content = content.replace(\"np.cast\", \"np.asarray\")\n",
    "\n",
    "    with open(tfonnx_path, 'w') as f:\n",
    "        f.write(updated_content)\n",
    "\n",
    "    print(\"Successfully attempted to patch tf2onnx.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to patch tf2onnx: {e}\")\n",
    "\n",
    "# Now, try the ONNX conversion again\n",
    "!python -m tf2onnx.convert --saved-model /content/drive/MyDrive/my_keras_models/sar_ship_detect_models/models --output sar_ship_u-net.onnx --opset 15"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOg2z1ho+DUDYqg4sO8niN4",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
